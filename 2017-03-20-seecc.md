---
layout: post
title: Working efficiently with large datasets
subtitle: Quantifying population change and visualising species occurrence
date: 2017-03-20 10:00:00
author: John, Gergana, Sandra and Isla
meta: "Tutorials"
---
<div class="block">
	<center>
		<img src="{{ site.baseurl }}/img/tutheaderbigdata.png" alt="Img">
	</center>
</div>

### Tutorial Aims:

#### <a href="#tidyr"> 1. Formatting and tidying data using `tidyr` </a>

#### <a href="#dplyr"> 2. Efficiently manipulating data using `dplyr` </a>

#### <a href="#loops_lapply"> 3. Automating data manipulation using `lapply()`, loops and pipes </a>

#### <a href="#datavis"> 4. Automating data visualisation using `ggplot2` and `dplyr` </a>

# Quantifying population change

This workshop will provide an overview of methods used to investigate an ecological research question using a big(ish) dataset that charts the population trends of ~15,000 animal populations from ~3500 species across the world, provided by the [Living Planet Index](http://www.livingplanetindex.org/home/index). We will use the LPI dataset to first examine how biodiversity has changed since 1970, both globally and at the biome scale, and then we will zoom in further to create a map of the distribution of the Atlantic puffin based on occurrence data from [GBIF](http://www.gbif.org/) and [Flickr](http://www.flickr.com/). We will be following a generic workflow that is applicable to most scientific endeavours, at least in the life sciences. This workflow can be summed up in this neat diagram we borrowed ([plagiarised](http://r4ds.had.co.nz)) from Hadley Wickham's book R for Data Science:

# INSERT FLOWCHART

Open up a new R Script where you will be adding the code for this tutorial. All the resources for this tutorial, including some helpful cheatsheets can be downloaded from [this repository](https://github.com/ourcodingclub/SEECC-workshop) Clone and download the repo as a zipfile, then unzip and set the folder as your working directory by running the code below (subbing in the actual folder path), or clicking `Session/ Set Working Directory/ Choose Directory` from the RStudio menu.

Alternatively, you can fork [the repository](https://github.com/ourcodingclub/SEECC-workshop) to your own Github account and then add it as a new RStudio project by copying the HTTPS/SSH link. For more details on how to register on Github, download Git, sync RStudio and Github and use version control, please check out our previous <a href="https://ourcodingclub.github.io/2017/02/27/git.html">tutorial.</a>

```r
setwd("PATH_TO_FOLDER")
```

Next, install (`install.packages("")`) and load (`library()`) the packages needed for this tutorial.

```r
install.packages("tidyr")
install.packages("dplyr")
install.packages("broom")
install.packages("ggplot2")
install.packages("ggExtra")
install.packages("maps")
install.packages("RColorBrewer")
install.packages("readr")

library(tidyr)
library(dplyr)
library(broom)
library(ggplot2)
library(ggExtra)
library(maps)
library(RColorBrewer)
library(readr)
```

Finally, load the `.RData` files we will be using for the tutorial. The data we originally downloaded from the LPI website was in a `.csv` format, but when handling large datasets, `.RData` files are quicker to use, since they are more compressed. Of course, a drawback would be that `.RData` files can only be used within R, whereas `.csv` files are more transferable.

```r
load("LPIdata_Feb2016.RData")
load("puffin_GBIF.RData")
```

<a name="tidyr"></a>

## 1. Formatting and tidying data using `tidyr`

### Reshaping data frames using `gather()`

The way you record information in the field or in the lab is probably very different to the way you want your data entered into R. In the field, you want tables that you can ideally draw up ahead and fill in as you go, and you will be adding notes and all sorts of information in addition to the data you want to analyse. For instance, if you monitor the height of seedlings during a factorial experiment using warming and fertilisation treatments, you might record your data like this:

<center> <img src="{{ site.baseurl }}/img/SAB_fig1.png" alt="Img" style="width: 500px;"/> </center>

Let's say you want to run a test to determine whether warming and/or fertilisation affected seedling growth. You may know how your experiment is set up, but R doesn't! At the moment, with 8 measures per row (combination of all treatments and species for one replicate, or block), you cannot run an analysis. On the contrary,
<a href="https://www.jstatsoft.org/article/view/v059i10">tidy datasets</a> are arranged so that each **row** represents an **observation** and each **column** represents a **variable**. In our case, this would look something like this:

<center> <img src="{{ site.baseurl }}/img/SAB_fig2.png" alt="Img" style="width: 400px;"/> </center>

This makes a much longer dataframe row-wise, which is why this form is often called *long format*. Now if you wanted to compare between groups, treatments, species, etc, R would be able to split the dataframe correctly, as each grouping factor has its own column.

The `gather()` function from the `tidyr` package lets you convert a wide-format data frame to a tidy long-format data frame.

Have a look at the first few columns of the LPI data set (`LPIdata_Feb2016`) to see whether it is tidy:

```r
View(head(LPIdata_Feb2016))
```

At the moment, each row contains a population that has been monitored over time and towards the right of the data frame there are lots of columns with population estimates for each year. To make this data "tidy" (one column per variable) we can use `gather()` to transform the data so there is a new column containing all the years for each population and an adjacent column containing all the population estimates for those years:

```r
LPI_long <- gather(data = LPIdata_Feb2016, key = "year", value = "pop", select = 26:70)
```

This takes our original dataset `LPIdata_Feb2016` and creates a new column called `year`, fills it with column names from columns `26:70` and then uses the data from these columns to make another column called `pop`.

Because column names are coded in as characters, when we turned the column names (`1970`, `1971`, `1972`, etc.) into rows, R automatically put an `X` in front of the numbers to force them to remain characters. We don't want that, so to turn `year` into a numeric variable, use:

```r
LPI_long$year <- parse_number(LPI_long$year)
```

### Using sensible variable names

Have a look at the column names in `LPI_long`:

```r
names(LPI_long)
```

The variable names are a mixture of upper and lower case letters and some use `.` to mark the end of a word. There are lots of conventions for [naming objects and variables in programming](https://journal.r-project.org/archive/2012-2/RJournal_2012-2_Baaaath.pdf) but for the sake of consistency and making things easier to read, let's replace any `.` with `_` using `gsub()`and make everything lower case using `tolower()`:

```r
names(LPI_long) <- gsub(".", "_", names(LPI_long), fixed = TRUE)
names(LPI_long) <- tolower(names(LPI_long))
```

Each population in the dataset can be identified using the `id` column, but to group our dataset by species, we would have to group first by `genus`, then by `species`, to prevent problems with species having similar names. To circumvent this, we can make a new column which holds the genus and species together using `paste()`:

```r
LPI_long$genus_species_id <- paste(LPI_long$genus, LPI_long$species, LPI_long$id, sep = "_")
```

Finally, lets look at a sample of the contents of the data frame to make sure all the variables are displayed properly:

```r
View(LPI_long[c(1:5,500:505,1000:1005),])
```

`country_list` and `biome` seem to have some helpful (annoying) `,` and `/` to separate entries. This could mess up our analyses so remove them using `gsub()` as before:

```r
LPI_long$country_list <- gsub(",", "", LPI_long$country_list, fixed = TRUE)
LPI_long$biome <- gsub("/", "", LPI_long$biome, fixed = TRUE)
```

That took a while, but I guarantee it's worth doing to avoid confusion later down the line.

<a name="dplyr"></a>

## 2. Efficiently manipulating data using `dplyr`

Now that our dataset is *tidy* we can get it ready for our analysis. This is quite a messy data frame with data from lots of different sources so to help answer our question of how biodiversity has changed since 1970, we should create some new variables and filter out the unnecessary data.

To make sure there are no duplicate rows, we can use `distinct()`:

```r
LPI_long <- distinct(LPI_long)
```

Then we can remove any rows that have missing or infite data:

```r
LPI_long <- filter(LPI_long, is.finite(pop))
```

Next, we want to only use populations that have more than 5 years of data, as population trend estimates from short term studies can be very inaccurate when projected into the future. To do this we can use pipes. Pipes (`%>%`) are a way of streamlining data manipulation - imagine all of your data coming in one end of the pipe, while they are in there, they are manipulated, summarised, etc., then the output (e.g. your new data frame or summary statistics) comes out the other end of the pipe. At each step of the pipe processing, you can tell the pipe what information to use - e.g. here we are using `.`, which just means "take the ouput of the previous step". For more information on data manipulation using pipes, you can check out our [data formatting and manipulation tutorial](https://ourcodingclub.github.io/2017/01/16/piping.html).

```r
LPI_long <- LPI_long %>%
	group_by(., genus_species_id) %>%  # group rows so that each group is one population
	mutate(., maxyear = max(year), minyear = min(year)) %>%  # Create columns for the first and most recent years that data was collected
	mutate(., lengthyear = maxyear-minyear) %>%  # Create a column for the length of time data available
	filter(., lengthyear > 5) %>%  # Only keep rows with more than 5 years of data
	ungroup(.)  # Remove any groupings you've greated in the pipe, not entirely necessary but it's better to be safe
```

Now we can explore our data a bit. Let's create a few basic summary statistics for each taxonomic class and store them in a new data frame:

```r
LPI_class_summ <- LPI_long %>%
  group_by(class) %>%  # Group by class
  summarise(populations = n(),   # Create columns, number of populations
            mean_study_length_years = mean(lengthyear),  # mean study length
            max_lat = max(decimal_latitude),  # max latitude
            min_lat = min(decimal_latitude),  # max longitude
            dominant_sampling_method = names(which.max(table(sampling_method))),  # modal sampling method
            dominant_units = names(which.max(table(units))))  # modal unit type
```

Check out the new data frame using `View(LPI_class_summ)` to find out how many populations each class has, as well as other summary information.

Now you can calculate more summary statistics and adjust the main data frame, which we will use in our analysis later:

```r
LPI_long <- LPI_long %>%
group_by(., common_name, genus_species_id, units) %>%  # Groups Measurement_type(Units)>population(id)>species(Common.Name+species)
 mutate(., scalepop = (pop-min(pop))/(max(pop)-min(pop))) %>%  # Scale population trend from 0 to 1
 filter(., is.finite(scalepop)) %>%  # Remove rows without a scalepop
 mutate(., meanpop = mean(pop)) %>%  # Create column for mean population
 ungroup(.) %>%
 group_by(., common_name, genus_species_id) %>%
 mutate(., meanpop.size = mean(meanpop)) %>%  # Create column for mean mean population
 ungroup(.)
```

<a name="lapply_loops"></a>

## 3. Automating data manipulation using `lapply()`, loops and pipes

Often we want to perform the same type of analysis on multiple species, plots, or any other groups within our data - copying and pasting is inefficient and can easily lead to mistakes, so it's much better to automate the process within R and avoid all the repetition. There are several ways to do this, including using `apply()` and it's variants, loops, and pipes. For more information, you can check out our tutorials on <a href="https://ourcodingclub.github.io/2017/02/08/funandloops.html">loops</a> and <a href="https://ourcodingclub.github.io/2017/01/16/piping.html">piping</a>, but for now, here is a brief summary.

The `apply()` function and it's variants (`lapply()`,`sapply()`, `tapply()`, `mapply()`) act as wrappers around other functions that you want to apply equally to items in an array (`apply()`), list (`lapply()`, `sapply()`), grouped vector (`tapply()`), or some other multivariate function (`mapply()`).

Loops are used for iterative purposes - through loops you are telling R to do something (calculate a mean, make a graph, anything) for each element of a certain list (could be a list of years, species, countries, any category within your data).

Pipes (`%>%`), as you found out above, are a way of streamlining the data manipulation process. Within the pipe you can group by categories of your choice, so for example we can calculate the LPI for different biomes or countries, and then save the plots.

INSERT TABLE OF PROS AND CONS OF EACH? Then go through examples from each category.

lapply cons -
lapply pros - quicker than loops

Loops cons - can take longer to run, use up more memory; people tend to hate them, so when you ask for help with your loop, people just say not to use a loop
Loops pros - but loops are easy to understand, they make logical sense and do a fair job when your dataset is not humongous, loops are used in lots of other programming languages

Pipes cons - can take a bit of fiddling around to adjust the code
Pipes pros - more efficient, you can have all your data manipulation, visualisation and graph exploring into one pipe, quicker than loops (This is to do with loops calling the same function multiple times, once for each iteration, function calls in R are a bottleneck)

Using our data set, we want to create linear models which demonstrate the abundance trend over time, for each of our populations, then extract model coefficients and other useful stuff to a data frame.

You can do this using `lapply()`:

```r
# Create a list of data frames by splitting `LPI_long` by population (`genus_species_id`)
LPI_long_list <- split(LPI_long, f = LPI_long$genus_species_id)  # This takes a couple minutes to run

# `lapply()` a linear model (`lm`) to each data frame in the list and store as a list of linear models
LPI_list_lm <- lapply(LPI_long_list, function(x) lm(scalepop ~ year, data = x))

# Extract model coefficients and store them in a data frame
LPI_models_lapply <- filter(data.frame(
  "genus_species_id" = names(LPI_list_lm),
  "n" = unlist(lapply(LPI_list_lm, function(x) df.residual(x))),
  "intercept" = unlist(lapply(LPI_list_lm, function(x) summary(x)$coeff[1])),
  "slope" = unlist(lapply(LPI_list_lm, function(x) summary(x)$coeff[2])),
  "intercept_se" = unlist(lapply(LPI_list_lm, function(x) summary(x)$coeff[3])),
  "slope_se" = unlist(lapply(LPI_list_lm, function(x) summary(x)$coeff[4])),
  "intercept_p" = unlist(lapply(LPI_list_lm, function(x) summary(x)$coeff[7])),
  "slope_p" = unlist(lapply(LPI_list_lm, function(x) summary(x)$coeff[8]))
  ), n > 5)
```

For the sake of completeness, here's how to do the same using a loop - the code takes hours to run!

```r
# !!! This takes hours to run !!!

# Create data frame to store results
LPI_models_loop <- data.frame()

for(i in unique(LPI_long$genus_species_id)) {
  frm <- as.formula(paste("scalepop ~ year"))
  mylm <- lm(formula = frm, data = LPI_long[LPI_long$genus_species_id == i,])
  sum <- summary(mylm)

  # Extract mylmel coefficients
  n <- df.residual(mylm)
  intercept <- summary(mylm)$coeff[1]
  slope <- summary(mylm)$coeff[2]
  intercept_se <- summary(mylm)$coeff[3]
  slope_se <- summary(mylm)$coeff[4]
  intercept_p <- summary(mylm)$coeff[7]
  slope_p <- summary(mylm)$coeff[8]

  # Create temporary data frame
  df <- data.frame(genus_species_id = i, n = n, intercept = intercept,
                   slope = slope, intercept_se = intercept_se, slope_se = slope_se,
                   intercept_p = intercept_p, slope_p = slope_p, stringsAsFactors = F)

  # Bind rows of temporary data frame to the LPI_mylmels_loop data frame
  LPI_models_loop <- rbind(LPI_models_loop, df)
}
```

Using pipes (this takes a few minutes to run):

```r
LPI_models_pipes <- LPI_long %>%
  group_by(., genus_species_id) %>%  # Groups Measurement_type(Units)>population(id)>species(Common.Name+species)
  do(mod = lm(scalepop ~ year, data = .)) %>%  # Create a linear model for each group
  mutate(., n = df.residual(mod),  # Create columns: degrees of freedom
         intercept=summary(mod)$coeff[1],  # intercept coefficient
         slope=summary(mod)$coeff[2],  # slope coefficient
         intercept_se=summary(mod)$coeff[3],  # standard error of intercept
         slope_se=summary(mod)$coeff[4],  # standard error of slope
         intercept_p=summary(mod)$coeff[7],  # p value of intercept
         slope_p=summary(mod)$coeff[8]) %>%  # p value of slope
  filter(., n > 5) # Remove rows where degrees of freedom <5
```

We used the `system.time()` function to time how long each of these methods took so you can easily compare:

<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}
.tg .tg-yw4l{vertical-align:top}
</style>
<table class="tg">
  <tr>
    <th class="tg-yw4l">Method</th>
    <th class="tg-yw4l">Total Elapsed Time (s)</th>
    <th class="tg-yw4l">User Space Time (s)</th>
    <th class="tg-yw4l">System Space Time (s)</th>
  </tr>
  <tr>
    <td class="tg-yw4l">loop</td>
    <td class="tg-yw4l">180.453</td>
    <td class="tg-yw4l">170.88</td>
    <td class="tg-yw4l">7.514</td>
  </tr>
  <tr>
    <td class="tg-yw4l">pipe</td>
    <td class="tg-yw4l">30.941</td>
    <td class="tg-yw4l">30.456</td>
    <td class="tg-yw4l">0.333</td>
  </tr>
  <tr>
    <td class="tg-yw4l">lapply</td>
    <td class="tg-yw4l">26.665</td>
    <td class="tg-yw4l">26.172</td>
    <td class="tg-yw4l">0.261</td>
  </tr>
</table>

You can do the same by wrapping any of the methods in `system.time()`:

```r
system.time(
	LPI_models_pipes <- LPI_long %>%
  group_by(., genus_species_id) %>%
  do(mod = lm(scalepop ~ year, data = .)) %>%
  mutate(., n = df.residual(mod),
         intercept=summary(mod)$coeff[1],
         slope=summary(mod)$coeff[2],
         intercept_se=summary(mod)$coeff[3],
         slope_se=summary(mod)$coeff[4],
         intercept_p=summary(mod)$coeff[7],
         slope_p=summary(mod)$coeff[8]) %>%
  filter(., n > 5)
	)
```

Now compare the three data frames to see that they are exactly the same!

Now that we have added all this extra information to the data frame, let's save it just in case R crashes or your laptop runs out of battery:

```r
save(LPI_models_pipes, file = "LPI_models_pipes.RData")
save(LPI_models_pipes, file = "LPI_models_pipes.csv")  # This takes a long time to save, don't run it unless you have time to wait.
```

Compare the `.RData` file with an equivalent `.csv` file. `.RData` files are much more compressed than `.csv` files, and load into R much more quickly. They are also guaranteed to be in the right format, unlike a `.csv`, which can have problems with quotes (`""`), commas (`,`) and unfinished lines. The only drawback being that they can't be used by other software.

<a name ="datavis"></a>

## 4. Automating data visualisation using `ggplot2` and `dplyr`
Now that we have quantified how the different populations in the LPI dataset have changed through time, it'd be great to visualise the results. First, we can explore how populations are changing in different biomes through a histogram of slope estimates. We could filter the data for each biome, make a new data frame, make the histogram, save it, and repeat all of this many times, or we could get it done all in one go using `ggplot2` and pipes `%>%`. Here we'll save the plots as `.pdf` files, but you could use `.png` as well. We will also set a custom theme for `ggplot2` to use when making the histograms and choose a colour for the bins using `Rcolourpicker`.

### Making your own `ggplot2` theme
If you've ever tried to perfect your `ggplot2` graphs, you might have noticed that the lines starting with ` + theme()` quickly pile up - you adjust the font size of the axes and the labels, the position of the title, the background colour of the plot, you remove the grid lines in the background, etc. And then you have to do the same for the next plot, which really increases the amount of code you use. Here is a simple solution - create a customised theme that combines all the `theme()` elements you want, and apply it to your graphs to make things easier and increase consistency. You can include as many elements in your theme as you want, as long as they don't contradict one another, and then when you apply your theme to a graph, only the relevant elements will be considered - e.g. for our histograms we won't need to use `legend.position`, but it's fine to keep it in the theme, in case any future graphs we apply it to do have the need for legends.

```r
theme_LPI <- function(){
  theme_bw()+
  theme(axis.text.x=element_text(size=12, angle=45, vjust=1, hjust=1),
        axis.text.y=element_text(size=12),
        axis.title.x=element_text(size=14, face="plain"),
        axis.title.y=element_text(size=14, face="plain"),
        panel.grid.major.x=element_blank(),
        panel.grid.minor.x=element_blank(),
        panel.grid.minor.y=element_blank(),
        panel.grid.major.y=element_blank(),
        plot.margin = unit(c(0.5, 0.5, 0.5, 0.5), units = , "cm"),
        plot.title = element_text(size=20, vjust=1, hjust=0.5),
        legend.text = element_text(size=12, face="italic"),
        legend.title = element_blank(),
        legend.position=c(0.9, 0.9))
}
```

### Picking colours using the `Rcolourpicker` addin
Setting custom colours for your graphs can set them apart from all the rest (we all know what the default `ggplot2` colours look like!), make them prettier, and most importantly, give your work a consistent and logical colour scheme. Finding the codes, e.g. `colour="#8B5A00"`, for your chosen colours, however, can be a bit tedious. Though one can always use Paint / Photoshop / google colour codes, there is a way to do this within RStudio thanks to the addin `colourpicker`. RStudio addins are installed the same way as packages, and you can access them by clicking on `Addins` in your RStudio menu. To install `colourpicker`, run the following code:

```r
install.packages("colourpicker")
```

To find out what is the code for a colour you like, click on `Addins/Colour picker`.

<center><img src="{{ site.baseurl }}/img/colourpicker.png" alt="Img" style="width: 800px;"/></center>

When you click on `All R colours` you will see lots of different colours you can choose from - a good colour scheme makes your graph stand out, but of course, don't go crazy with the colours. When you click on `1`, and then on a certain colour, you fill up `1` with that colour, same goes for `2`, `3` - you can add mode colours with the `+`, or delete them by clicking the bin. Once you've made your pick, click `Done`. You will see a line of code `c("#8B5A00", "#CD8500")` appear - in this case, we just need the colour code, so we can copy that, and delete the rest.

<center><img src="{{ site.baseurl }}/img/colourpicker2.png" alt="Img" style="width: 800px;"/></center>

### Plotting histograms of population change in different biomes and saving them

```r
biome.plots <- as.data.frame(LPI_long) %>%
  group_by(., genus_species_id) %>%
  do(mod = lm(scalepop ~ year, data = .)) %>%
  tidy(mod) %>%
  ungroup() %>%
  group_by(., biome) %>%
  do(ggsave(ggplot(.,aes(x = estimate)) + geom_histogram(colour="#8B5A00", fill="#CD8500") + theme_LPI(),
            filename = gsub("", "", paste("Biome_LPI/", unique(as.character(.$biome)), ".pdf", sep="")), device = "pdf"))
```

### Ploting slope estimates for population change and adding histograms along the margins
Within RStudio, you can use addins, including `Rcolourpicker` that we dicussed above, and `ggExtra` that we will use for our marginal histograms.

Once you've installed the package by running `install.packages("ggExtra")`, you can select `ggplot2` code, click on `ggplot2 Marginal Histograms` from the Addin menu and build your plot. Copy the code for the plot and add it to your script afterwards.

<center><img src="{{ site.baseurl }}/img/ggextra1.png" alt="Img" style="width: 800px;"/></center>

Here is the final graph - what do you think, how has biodiversity changed in the last 40 years?

## TO BE INSERTED ONCE MY LAPTOP RECOVERS FROM THE LOOP SHOCK

## Visualising species occurrence

### Puffin GBIF
As an intro to the next section of the workshop, we're going to have a look at the distribution of the Atlantic Puffin, using public data from the [Global Biodiversity Information Facility](http://www.gbif.org), found in `puffin_GBIF.RData`.

Firstly, use `borders()` to pull some world map data from the `maps` package:

```r
map_world <- borders(database = "world", colour = "gray50", fill = "#383838")  # We used the `Colour Picker` Addin to pick the colours
```

Then create the plot using `ggplot()`:

```r
ggplot() + map_world +  # Plot the map
  geom_point(data = puffin_GBIF,  # Specify the data for geom_point()
             aes(x = decimallongitude,  # Specify the x axis as longitude
                 y = decimallatitude,  # Specify the y axis as latitude
                 colour = scientificname),  # Colour the points based on species name
             alpha = 0.4,  # Set point opacity to 40%
             size = 1) +  # Set point size to 1
  scale_color_brewer(palette = "Set1") +   # Specify the colour palette to colour the points
  theme_classic() +  # Remove gridlines and shading inside the plot
  ylab(expression("Latitude ("*degree*")" )) +  # Add a smarter x axis label
  xlab(expression("Longitude ("*degree*")" )) +  # Add a smarter y axis label
  theme(legend.position = "bottom",  # Move the legend to below the plot
        legend.title = element_blank())  # Remove the legend title
```

We used a colour palette from `RColorBrewer` to colour the points (`Set1`). You can see all the colour palettes by running `display.brewer.all()` in R.

## Over to Francesca
